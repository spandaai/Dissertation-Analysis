## Overview

The **Dissertation Analysis System** is designed to evaluate and analyze dissertations submitted by graduate students. This system leverages advanced analytics to assess the quality, originality, and impact of dissertations, helping academic committees ensure high standards in research outputs. With integration into Apache Superset, the system provides insightful visualizations and metrics for comprehensive dissertation assessment.

---
## About Client  
The client is a leading academic institution serving over 45,000 working professionals in its Work Integrated Learning Program (WILP). Renowned for its innovative approach to education, the institution emphasizes excellence in research and academic training.  

---

## Objective of the App (Project)  
To design a **Dissertation Analysis System** that evaluates and analyzes graduate dissertations for originality, quality, and academic impact while providing actionable insights to improve research programs.  

---

## Spanda's Solution Description  
Spanda proposes a cutting-edge **Dissertation Analysis System** incorporating:  
- **Multi-Agent LLM Evaluation Process**: A sophisticated multi-agent system leveraging various open-source tools to provide comprehensive analysis.  
- **Cluster of Open-Source LLMs**: Flexible integration with a cluster of open-source language models, ensuring scalable and cost-efficient analysis.  
- **Customizable Evaluation Criteria**: Adapts to specific departmental needs for tailored assessments.  
- **Feedback-Driven Improvement**: Integrates human feedback to refine and enhance evaluation models iteratively.  
- **Dataset Creation**: Builds a valuable dataset from evaluation processes, enabling the client to:  
  - Participate in academic marketplaces.  
  - Develop customized AI models using their dataset.  
- **Apache Superset Dashboards**: Provides real-time visual analytics for insightful decision-making.  

---

## Client Problems & Value Addition  
- **Initial Challenge**: WILP lacked a streamlined system for providing comprehensive feedback and actionable results for dissertations.  
- **Spanda's Solution**: Delivered a fully streamlined system, empowering WILP evaluators with detailed feedback to refine their processes and improve dissertation quality.  
- **Empowering Evaluators**: The system facilitates fine-tuning by leveraging feedback, enabling evaluators to enhance curriculum and research standards.  
- **Dataset Utilization**: Enables the client to create datasets for marketplaces or custom AI models, driving innovation and additional revenue opportunities.  

---

## Technology Landscape  
1. **Backend Frameworks**: Python-based frameworks for robust processing and analysis.  
2. **Machine Learning Models**: Algorithms for originality detection, quality analysis, and customization.  
3. **Multi-Agent System**: Coordination between agents to evaluate dissertations using diverse open-source LLMs.  
4. **Visualization Tools**: Apache Superset for intuitive dashboards and analytics.  
5. **Cloud Infrastructure**: Secure and scalable deployment on private or hybrid cloud environments.  
6. **Database**: SQL/NoSQL databases for managing dissertations and evaluation data.

---

## Key Statistics/Numbers  
- **Effort**: 1 month.  
- **Team**: 2 developers, 1 project manager.
- **Target Users**:  
  - **Pilot Phase**: 20 users.  
  - **Campus-Wide Rollout**: Faculty and academic committees (~500â€“1000 users).  
- **Benefits**:  
  - Streamlined feedback delivery and reporting system.  
  - Dataset creation capabilities for academic innovation and marketplaces. This can further be used to create models/LLMs which can be leveraged in our marketplace.
  - Enhanced evaluator efficiency and research quality.  