version: '3.8'
services:
  dissertation-backend:
    build:
      context: ../
      dockerfile: Dockerfile
    ports:
      - "8007:8006"
    env_file:
      - .env
    command: ["da-start"]
    networks:
      - app_network
    depends_on:
      - kafka
      - redis

  dissertation-frontend:
    image: prabhas264/dissertation-frontend:1.0.0
    restart: always
    ports:
      - "4000:4000"
    environment:
      - REACT_APP_API_URL=${REACT_APP_API_URL}
    networks:
      - app_network

  zookeeper:
    image: confluentinc/cp-zookeeper:7.8.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    networks:
      - app_network

  kafka:
    image: confluentinc/cp-kafka:7.8.0
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_MESSAGE_MAX_BYTES: 200000000  # 200 MB
      KAFKA_REPLICA_FETCH_MAX_BYTES: 200000000  # 200 MB
    depends_on:
      - zookeeper
    networks:
      - app_network

  redis:
    image: redis:alpine
    container_name: redis
    ports:
      - "6379:6379"
    networks:
      - app_network


  ollama:
    image: ollama/ollama:0.5.1
    container_name: ollama
    ports:
      - "11434:11434"
    volumes:
      - ~/.cache/huggingface:/root/.cache/huggingface
    networks:
      - app_network
    restart: unless-stopped
<<<<<<< HEAD:Docker-build/docker-compose.yml
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility

=======
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        reservations:
          devices:
            - driver: "nvidia"
              count: all
              capabilities: [gpu]
>>>>>>> test:Docker/docker-compose-build-gpu.yml

  mysql:
    image: mysql:8.0
    environment:
      MYSQL_ROOT_PASSWORD: Spanda@123
      MYSQL_DATABASE: feedbackDb
    ports:
      - "3306:3306"
    volumes:
      - mysql_data:/var/lib/mysql
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      - app_network

volumes:
  mysql_data:
    driver: local
  ollama:
    driver: local

networks:
  app_network:
    external: true

  # vllmnemotrontext:
  #   image: vllm/vllm-openai:latest
  #   runtime: nvidia
  #   restart: always
  #   env_file: 
  #     - .env
  #   environment:
  #     - HUGGING_FACE_HUB_TOKEN=${HF_TOKEN}
  #   ports:
  #     - "8001:8000"
  #   volumes:
  #     - ~/.cache/huggingface:/root/.cache/huggingface
  #   command: >  #change the model parameters accordingly
  #     --model AMead10/Llama-3.2-3B-Instruct-AWQ 
  #   ipc: host
  #   networks:
  #     - app_network
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - driver: nvidia
  #             count: all
  #             capabilities: [gpu]
  # vllmqwenvision:
  #   image: vllm/vllm-openai:latest
  #   runtime: nvidia
  #   restart: always
  #   env_file: 
  #     - .env
  #   environment:
  #     - HUGGING_FACE_HUB_TOKEN=${HF_TOKEN}
  #   ports:
  #     - "8002:8000"
  #   volumes:
  #     - ~/.cache/huggingface:/root/.cache/huggingface
  #   command: > #change the model parameters accordingly
  #     --model Qwen/Qwen2-VL-2B-Instruct-AWQ
  #   ipc: host
  #   networks:
  #     - app_network
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - driver: nvidia
  #             count: all
  #             capabilities: [gpu]
