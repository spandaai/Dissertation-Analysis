
version: '3.8'
services:
  dissertation-backend:
    image: prabhas264/dissertation-backend
    ports:
      - "8007:8006"
    env_file:
      - .env
    command: ["da-start"]
    networks:
      - app_network
    depends_on:
      - kafka
      - redis
  dissertation-frontend:
    image: prabhas264/dissertation-frontend:newUrl
    restart: always
    ports:
      - "4000:4000"
    environment:
      - REACT_APP_API_URL=${REACT_APP_API_URL}
    networks:
      - app_network
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    networks:
      - app_network
  kafka:
    image: confluentinc/cp-kafka:latest
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_MESSAGE_MAX_BYTES: 200000000  # 200 MB
      KAFKA_REPLICA_FETCH_MAX_BYTES: 200000000  # 200 MB
    depends_on:
      - zookeeper
    networks:
      - app_network
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: "local"
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: "kafka:9092"
    depends_on:
      - kafka
    networks:
      - app_network
  redis:
    image: redis:alpine
    container_name: redis
    ports:
      - "6379:6379"
    networks:
      - app_network
  vllmnemotrontext:
    image: vllm/vllm-openai:latest
    runtime: nvidia
    restart: always
    env_file: 
      - .env
    environment:
      - HUGGING_FACE_HUB_TOKEN=${HF_TOKEN}
    ports:
      - "8001:8000"
    volumes:
      - ~/.cache/huggingface:/root/.cache/huggingface
    command: >  #change the model parameters accordingly
      --model AMead10/Llama-3.2-3B-Instruct-AWQ 
    ipc: host
    networks:
      - app_network
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
  vllmqwenvision:
    image: vllm/vllm-openai:latest
    runtime: nvidia
    restart: always
    env_file: 
      - .env
    environment:
      - HUGGING_FACE_HUB_TOKEN=${HF_TOKEN}
    ports:
      - "8002:8000"
    volumes:
      - ~/.cache/huggingface:/root/.cache/huggingface
    command: > #change the model parameters accordingly
      --model Qwen/Qwen2-VL-2B-Instruct-AWQ
    ipc: host
    networks:
      - app_network
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
  mysql:
    image: mysql:8.0
    environment:
      MYSQL_ROOT_PASSWORD: Spanda@123
      MYSQL_DATABASE: feedbackDb
    ports:
      - "3306:3306"
    volumes:
      - mysql_data:/var/lib/mysql
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      - app_network
volumes:
  mysql_data:
    driver: local
networks:
  app_network:
    external: true
